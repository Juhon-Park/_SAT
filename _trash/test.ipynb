{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Adapted from\n",
    "# https://github.com/zzzxxxttt/pytorch_DoReFaNet/blob/master/utils/quant_dorefa.py and\n",
    "# https://github.com/tensorpack/tensorpack/blob/master/examples/DoReFa-Net/dorefa.py#L25\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SwitchBatchNorm2d(nn.Module):\n",
    "    \"\"\"Adapted from https://github.com/JiahuiYu/slimmable_networks\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, bit_list):\n",
    "        super(SwitchBatchNorm2d, self).__init__()\n",
    "        self.bit_list = bit_list\n",
    "        self.bn_dict = nn.ModuleDict()\n",
    "        for i in self.bit_list:\n",
    "            self.bn_dict[str(i)] = nn.BatchNorm2d(num_features)\n",
    "\n",
    "        self.abit = self.bit_list[-1]\n",
    "        self.wbit = self.bit_list[-1]\n",
    "        if self.abit != self.wbit:\n",
    "            raise ValueError('Currenty only support same activation and weight bit width!')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_dict[str(self.abit)](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def batchnorm2d_fn(bit_list):\n",
    "    class SwitchBatchNorm2d_(SwitchBatchNorm2d):\n",
    "        def __init__(self, num_features, bit_list=bit_list):\n",
    "            super(SwitchBatchNorm2d_, self).__init__(num_features=num_features, bit_list=bit_list)\n",
    "\n",
    "    return SwitchBatchNorm2d_\n",
    "\n",
    "\n",
    "class SwitchBatchNorm1d(nn.Module):\n",
    "    \"\"\"Adapted from https://github.com/JiahuiYu/slimmable_networks\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, bit_list):\n",
    "        super(SwitchBatchNorm1d, self).__init__()\n",
    "        self.bit_list = bit_list\n",
    "        self.bn_dict = nn.ModuleDict()\n",
    "        for i in self.bit_list:\n",
    "            self.bn_dict[str(i)] = nn.BatchNorm1d(num_features)\n",
    "\n",
    "        self.abit = self.bit_list[-1]\n",
    "        self.wbit = self.bit_list[-1]\n",
    "        if self.abit != self.wbit:\n",
    "            raise ValueError('Currenty only support same activation and weight bit width!')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_dict[str(self.abit)](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def batchnorm1d_fn(bit_list):\n",
    "    class SwitchBatchNorm1d_(SwitchBatchNorm1d):\n",
    "        def __init__(self, num_features, bit_list=bit_list):\n",
    "            super(SwitchBatchNorm1d_, self).__init__(num_features=num_features, bit_list=bit_list)\n",
    "\n",
    "    return SwitchBatchNorm1d_\n",
    "\n",
    "\n",
    "class qfn(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, k):\n",
    "        n = float(2**k - 1)\n",
    "        out = torch.round(input * n) / n\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input, None\n",
    "\n",
    "\n",
    "class weight_quantize_fn(nn.Module):\n",
    "    def __init__(self, bit_list):\n",
    "        super(weight_quantize_fn, self).__init__()\n",
    "        self.bit_list = bit_list\n",
    "        self.wbit = self.bit_list[-1]\n",
    "        assert self.wbit <= 8 or self.wbit == 32\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.wbit == 32:\n",
    "            E = torch.mean(torch.abs(x)).detach()\n",
    "            weight = torch.tanh(x)\n",
    "            weight = weight / torch.max(torch.abs(weight))\n",
    "            weight_q = weight * E\n",
    "        else:\n",
    "            E = torch.mean(torch.abs(x)).detach()\n",
    "            weight = torch.tanh(x)\n",
    "            weight = weight / 2 / torch.max(torch.abs(weight)) + 0.5\n",
    "            weight_q = 2 * qfn.apply(weight, self.wbit) - 1\n",
    "            weight_q = weight_q * E\n",
    "        return weight_q\n",
    "\n",
    "\n",
    "class activation_quantize_fn(nn.Module):\n",
    "    def __init__(self, bit_list):\n",
    "        super(activation_quantize_fn, self).__init__()\n",
    "        self.bit_list = bit_list\n",
    "        self.abit = self.bit_list[-1]\n",
    "        assert self.abit <= 8 or self.abit == 32\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.abit == 32:\n",
    "            activation_q = x\n",
    "        else:\n",
    "            activation_q = qfn.apply(x, self.abit)\n",
    "        return activation_q\n",
    "\n",
    "\n",
    "class Conv2d_Q(nn.Conv2d):\n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        super(Conv2d_Q, self).__init__(*kargs, **kwargs)\n",
    "\n",
    "\n",
    "def conv2d_quantize_fn(bit_list):\n",
    "    class Conv2d_Q_(Conv2d_Q):\n",
    "        def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1,\n",
    "                     bias=True):\n",
    "            super(Conv2d_Q_, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups,\n",
    "                                            bias)\n",
    "            self.bit_list = bit_list\n",
    "            self.w_bit = self.bit_list[-1]\n",
    "            self.quantize_fn = weight_quantize_fn(self.bit_list)\n",
    "\n",
    "        def forward(self, input, order=None):\n",
    "            weight_q = self.quantize_fn(self.weight)\n",
    "            return F.conv2d(input, weight_q, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
    "\n",
    "    return Conv2d_Q_\n",
    "\n",
    "\n",
    "class Linear_Q(nn.Linear):\n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        super(Linear_Q, self).__init__(*kargs, **kwargs)\n",
    "\n",
    "\n",
    "def linear_quantize_fn(bit_list):\n",
    "    class Linear_Q_(Linear_Q):\n",
    "        def __init__(self, in_features, out_features, bias=True):\n",
    "            super(Linear_Q_, self).__init__(in_features, out_features, bias)\n",
    "            self.bit_list = bit_list\n",
    "            self.w_bit = self.bit_list[-1]\n",
    "            self.quantize_fn = weight_quantize_fn(self.bit_list)\n",
    "\n",
    "        def forward(self, input):\n",
    "            weight_q = self.quantize_fn(self.weight)\n",
    "            return F.linear(input, weight_q, self.bias)\n",
    "\n",
    "    return Linear_Q_\n",
    "\n",
    "\n",
    "batchnorm_fn = batchnorm2d_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 32, 32])\n",
      "torch.Size([16, 8, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# initialize conv2d_q layer with random weights\n",
    "conv2d = conv2d_quantize_fn([4])\n",
    "conv_org = conv2d(in_channels=16, out_channels=8*2, kernel_size=3, stride=1, padding=1, bias=False, groups=2)\n",
    "\n",
    "# initialize random input tensor\n",
    "input = torch.rand(1, 16, 32, 32)\n",
    "\n",
    "# forward pass\n",
    "output = conv_org(input)\n",
    "print(output.shape)\n",
    "print(conv_org.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# low rank convolution\n",
    "rank = 8\n",
    "conv_R = conv2d(in_channels=16, out_channels=rank, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "conv_L = conv2d(in_channels=rank, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "# forward pass\n",
    "output = conv_R(input)\n",
    "output = conv_L(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d_Q_LR(nn.Module):\n",
    "    def __init__(self, *kargs, **kwargs):\n",
    "        super(Conv2d_Q_LR, self).__init__(*kargs, **kwargs)\n",
    "\n",
    "def conv2d_lr_quantize_fn(bit_list):\n",
    "    class Conv2d_Q_LR_(Conv2d_Q_LR):\n",
    "        def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1,\n",
    "                    bias=True, rank=8):\n",
    "            super(Conv2d_Q_LR_, self).__init__()\n",
    "            self.stride = stride\n",
    "            self.rank = in_channels // 2\n",
    "            self.groups = 4\n",
    "            # if in_channels == 64:\n",
    "            #     self.groups = 1\n",
    "            # elif in_channels == 32:\n",
    "            #     self.groups = 2\n",
    "            # elif in_channels == 16:\n",
    "            #     self.groups = 4\n",
    "            conv2d = conv2d_quantize_fn(bit_list)\n",
    "            if stride == 1:\n",
    "                self.conv_R = conv2d(in_channels=in_channels, \n",
    "                                    out_channels=self.rank*self.groups, \n",
    "                                    kernel_size=kernel_size, \n",
    "                                    stride=stride, \n",
    "                                    padding=padding, \n",
    "                                    bias=False, \n",
    "                                    groups=groups)\n",
    "                self.conv_L = conv2d(in_channels=self.rank*self.groups, \n",
    "                                    out_channels=out_channels, \n",
    "                                    kernel_size=kernel_size, \n",
    "                                    stride=stride, \n",
    "                                    padding=padding, \n",
    "                                    bias=False)\n",
    "            else:\n",
    "                self.conv_ds = conv2d(in_channels=in_channels, \n",
    "                                        out_channels=out_channels, \n",
    "                                        kernel_size=kernel_size, \n",
    "                                        stride=stride, \n",
    "                                        padding=padding, \n",
    "                                        bias=False)\n",
    "\n",
    "        def forward(self, x):\n",
    "            if self.stride == 1:\n",
    "                x = self.conv_R(x)\n",
    "                x = self.conv_L(x)\n",
    "            else:\n",
    "                x = self.conv_ds(x)\n",
    "            return x\n",
    "        \n",
    "    return Conv2d_Q_LR_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv2d_lr_quantize_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conv_lr \u001b[38;5;241m=\u001b[39m \u001b[43mconv2d_lr_quantize_fn\u001b[49m([\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m      2\u001b[0m conv0 \u001b[38;5;241m=\u001b[39m conv_lr(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m conv0(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv2d_lr_quantize_fn' is not defined"
     ]
    }
   ],
   "source": [
    "conv_lr = conv2d_lr_quantize_fn([4])\n",
    "conv0 = conv_lr(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "output = conv0(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d_Q_LR_(\n",
       "  (conv_R): Conv2d_Q_(\n",
       "    16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (quantize_fn): weight_quantize_fn()\n",
       "  )\n",
       "  (conv_L): Conv2d_Q_(\n",
       "    8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "    (quantize_fn): weight_quantize_fn()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "# low rank convolution\n",
    "rank = 8\n",
    "conv_R = conv2d(in_channels=16, out_channels=rank, kernel_size=3, stride=1, padding=1, bias=False, groups=2)\n",
    "conv_L = conv2d(in_channels=rank, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "# forward pass\n",
    "output = conv_R(input)\n",
    "output = conv_L(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "rank = 8\n",
    "groups = 4\n",
    "conv_R = conv2d(in_channels=16, out_channels=rank*groups, kernel_size=3, stride=1, padding=1, bias=False, groups=groups)\n",
    "print(conv_R.weight.shape)\n",
    "\n",
    "# output = conv_R(input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152\n"
     ]
    }
   ],
   "source": [
    "# check the number of parameters in conv_R\n",
    "print(sum(p.numel() for p in conv_R.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_R.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "rank = 8\n",
    "conv_R = conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False, groups=1)\n",
    "\n",
    "output = conv_R(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreActResNet(\n",
       "  (conv0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-2): 3 x PreActBasicBlockQ(\n",
       "      (bn0): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act0): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv0): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "      (bn1): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act1): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv1): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): PreActBasicBlockQ(\n",
       "      (bn0): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act0): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv0): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "      (bn1): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act1): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv1): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "      (skip_conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skip_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4-5): 2 x PreActBasicBlockQ(\n",
       "      (bn0): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act0): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv0): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "      (bn1): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act1): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv1): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PreActBasicBlockQ(\n",
       "      (bn0): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act0): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv0): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "      (bn1): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act1): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv1): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "      (skip_conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (skip_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7-8): 2 x PreActBasicBlockQ(\n",
       "      (bn0): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act0): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv0): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "      (bn1): SwitchBatchNorm2d_(\n",
       "        (bn_dict): ModuleDict(\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act1): Activate(\n",
       "        (acti): ReLU(inplace=True)\n",
       "        (quan): activation_quantize_fn()\n",
       "      )\n",
       "      (conv1): Conv2d_Q_LR_(\n",
       "        (conv_R): Conv2d_Q_(\n",
       "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "        (conv_L): Conv2d_Q_(\n",
       "          128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "          (quantize_fn): weight_quantize_fn()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn): SwitchBatchNorm2d_(\n",
       "    (bn_dict): ModuleDict(\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet20q\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# get the numnber of parameters in the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad))\n",
      "File \u001b[0;32m~/LowRankforPIM/models/resnet_quan.py:202\u001b[0m, in \u001b[0;36mresnet20q\u001b[0;34m(bit_list, rank, groups, num_classes)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresnet20q\u001b[39m(bit_list, rank, groups, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPreActResNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPreActBasicBlockQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbit_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'num_classes'"
     ]
    }
   ],
   "source": [
    "import models \n",
    "\n",
    "model = models.__dict__['resnet20q'](bit_list=[4], rank=2, groups=1, num_classes=10)\n",
    "# get the numnber of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
