{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Training')\n",
    "parser.add_argument('--results-dir', default='./results', help='results dir')\n",
    "parser.add_argument('--dataset', default='imagenet', help='dataset name or folder')\n",
    "parser.add_argument('--train_split', default='train', help='train split name')\n",
    "parser.add_argument('--model', default='resnet18', help='model architecture')\n",
    "parser.add_argument('--workers', default=0, type=int, help='number of data loading workers')\n",
    "parser.add_argument('--epochs', default=200, type=int, help='number of epochs')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, help='manual epoch number')\n",
    "parser.add_argument('--batch-size', default=128, type=int, help='mini-batch size')\n",
    "parser.add_argument('--optimizer', default='sgd', help='optimizer function used')\n",
    "parser.add_argument('--lr', default=0.1, type=float, help='initial learning rate')\n",
    "parser.add_argument('--lr_decay', default='100,150,180', help='lr decay steps')\n",
    "parser.add_argument('--weight-decay', default=3e-4, type=float, help='weight decay')\n",
    "parser.add_argument('--print-freq', '-p', default=20, type=int, help='print frequency')\n",
    "parser.add_argument('--pretrain', default=None, help='path to pretrained full-precision checkpoint')\n",
    "parser.add_argument('--resume', default=None, help='path to latest checkpoint')\n",
    "parser.add_argument('--bit_width_list', default='4', help='bit width list')\n",
    "parser.add_argument('--wandb_log', default=True, type=bool, help='use wandb logging feature')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# # First add the following argument to your argparse. If the parameter is True, wandb will be used for logging\n",
    "# parser.add_argument('--wandb_log', default=False, type=bool, help='use wandb logging feature')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "# wandb_log is True, import wandb_ez package and initialize a run and pass args that we have defined above as arguments to the init funciton. \n",
    "# args should contatin all the parameters involved in the experiment.\n",
    "def dummy_func():\n",
    "    return\n",
    "\n",
    "if args.wandb_log:\n",
    "    from wandb_ez import wandb_ez\n",
    "    run = wandb_ez.init(args,dummy_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| asdict(self): {'act_bit_width': 4,\n",
      "                   'batch_size': 512,\n",
      "                   'dataset': 'cifar10',\n",
      "                   'epochs': 200,\n",
      "                   'groups': 1,\n",
      "                   'lr': 0.1,\n",
      "                   'lr_decay': '100,150,180',\n",
      "                   'model': 'resnet20q',\n",
      "                   'optimizer': 'sgd',\n",
      "                   'pretrain': None,\n",
      "                   'print_freq': 20,\n",
      "                   'rank': 1,\n",
      "                   'results_dir': './results',\n",
      "                   'resume': None,\n",
      "                   'scheduler': 'multi',\n",
      "                   'start_epoch': 0,\n",
      "                   'train_split': 'train',\n",
      "                   'wandb_log': False,\n",
      "                   'weight_bit_width': 4,\n",
      "                   'weight_decay': 0.0005,\n",
      "                   'workers': 2}\n",
      "ic| asdict(self): {'LR_enabled': False, 'groups': None, 'rank': None}\n",
      "ic| asdict(self): {'key': 'e0c11d3ff2bee4c8775ba05863038fdac671c043',\n",
      "                   'project': 'wandb_plugin_dev_test',\n",
      "                   'sweep_config': {'method': 'grid',\n",
      "                                    'metric': {'goal': 'maximize', 'name': 'Best_score'}},\n",
      "                   'sweep_count': 5,\n",
      "                   'sweep_enabled': True,\n",
      "                   'sweep_id': None}\n",
      "ic| all_cfg: all_cfg_dc(results_dir='./results', dataset='cifar10', train_split='train', model='resnet20q', workers=2, epochs=200, start_epoch=0, batch_size=512, optimizer='sgd', scheduler='multi', lr=0.1, lr_decay='100,150,180', weight_decay=0.0005, print_freq=20, pretrain=None, resume=None, weight_bit_width=4, act_bit_width=4, rank=None, groups=None, wandb_log=False, LR_enabled=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "all_cfg_dc(results_dir='./results', dataset='cifar10', train_split='train', model='resnet20q', workers=2, epochs=200, start_epoch=0, batch_size=512, optimizer='sgd', scheduler='multi', lr=0.1, lr_decay='100,150,180', weight_decay=0.0005, print_freq=20, pretrain=None, resume=None, weight_bit_width=4, act_bit_width=4, rank=None, groups=None, wandb_log=False, LR_enabled=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from configs.config import *\n",
    "\n",
    "ic(all_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.config_dataclass import *\n",
    "\n",
    "config_dict = {\n",
    "    \"results_dir\": \"./results\",\n",
    "    \"dataset\": \"cifar10\",\n",
    "    \"train_split\": \"train\",\n",
    "    \"model\": \"resnet20q\",\n",
    "    \"workers\": 2,\n",
    "    \"epochs\": 200,\n",
    "    \"start_epoch\": 0,\n",
    "    \"batch_size\": 512,\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"scheduler\": \"multi\",\n",
    "    \"lr\": 0.1,\n",
    "    \"lr_decay\": \"100,150,180\",\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"print_freq\": 20,\n",
    "    \"pretrain\": None,\n",
    "    \"resume\": None,\n",
    "    \"weight_bit_width\": 4,\n",
    "    \"act_bit_width\": 4,\n",
    "    \"rank\": 1,\n",
    "    \"groups\": 1,\n",
    "    \"wandb_log\": False,\n",
    "}\n",
    "\n",
    "config_dataclass = NN_config(**config_dict)\n",
    "\n",
    "\n",
    "LR_config_dict = {\n",
    "    \"LR_enabled\": False,\n",
    "    \"rank\": 1,\n",
    "    \"groups\": 1\n",
    "}\n",
    "\n",
    "LR_config_dc = LR_config(**LR_config_dict)\n",
    "\n",
    "wandb_cfg = {\n",
    "    \"key\": \"e0c11d3ff2bee4c8775ba05863038fdac671c043\",\n",
    "    \"project\": \"wandb_plugin_dev_test\",\n",
    "    \"sweep_enabled\": True,\n",
    "    \"sweep_config\": {\n",
    "        \"method\": \"grid\",\n",
    "        \"metric\": {\"goal\": \"maximize\", \"name\": \"Best_score\"}\n",
    "    },\n",
    "    \"sweep_count\": 5,\n",
    "    \"sweep_id\": None\n",
    "}\n",
    "\n",
    "wandb_config_instance = wandb_config(**wandb_cfg)\n",
    "\n",
    "\n",
    "combined_dict = combine_dc_to_dict([config_dataclass, LR_config_dc])\n",
    "all_config = create_dc_from_dict(\"all_config\", combined_dict)\n",
    "all_config_instance = all_config(**combined_dict)\n",
    "\n",
    "# ic(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icecream as ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Training')\n",
    "parser.add_argument('--results-dir', default='./results', help='results dir')\n",
    "parser.add_argument('--dataset', default='imagenet', help='dataset name or folder')\n",
    "parser.add_argument('--train_split', default='train', help='train split name')\n",
    "parser.add_argument('--model', default='resnet18', help='model architecture')\n",
    "parser.add_argument('--workers', default=0, type=int, help='number of data loading workers')\n",
    "parser.add_argument('--epochs', default=200, type=int, help='number of epochs')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, help='manual epoch number')\n",
    "parser.add_argument('--batch-size', default=128, type=int, help='mini-batch size')\n",
    "parser.add_argument('--optimizer', default='sgd', help='optimizer function used')\n",
    "parser.add_argument('--scheduler', default='cosine', help='scheduler used')\n",
    "parser.add_argument('--lr', default=0.1, type=float, help='initial learning rate')\n",
    "parser.add_argument('--lr_decay', default='100,150,180', help='lr decay steps')\n",
    "parser.add_argument('--weight-decay', default=3e-4, type=float, help='weight decay')\n",
    "parser.add_argument('--print-freq', '-p', default=20, type=int, help='print frequency')\n",
    "parser.add_argument('--pretrain', default=None, help='path to pretrained full-precision checkpoint')\n",
    "parser.add_argument('--resume', default=None, help='path to latest checkpoint')\n",
    "parser.add_argument('--bit_width_list', default='4', help='weight bit width list')\n",
    "parser.add_argument('--act_bit_width_list', default='4', help='activation bit width list')\n",
    "parser.add_argument('--rank', default=1, type=int, help='divider to get the rank')\n",
    "parser.add_argument('--groups', default=1, type=int, help='number of groups')\n",
    "parser.add_argument('--wandb_log', default=False, type=bool, help='use wandb logging feature')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_dir: ./results\n",
      "dataset: imagenet\n",
      "train_split: train\n",
      "model: resnet18\n",
      "workers: 0\n",
      "epochs: 200\n",
      "start_epoch: 0\n",
      "batch_size: 128\n",
      "optimizer: sgd\n",
      "scheduler: cosine\n",
      "lr: 0.1\n",
      "lr_decay: 100,150,180\n",
      "weight_decay: 0.0003\n",
      "print_freq: 20\n",
      "pretrain: None\n",
      "resume: None\n",
      "bit_width_list: 4\n",
      "act_bit_width_list: 4\n",
      "rank: 1\n",
      "groups: 1\n",
      "wandb_log: False\n"
     ]
    }
   ],
   "source": [
    "# Assuming args is the namespace returned by parser.parse_args()\n",
    "config = vars(args)\n",
    "\n",
    "# Printing the config dictionary to verify its contents\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_config(results_dir='./results', dataset='cifar10', train_split='train', model='resnet20q', workers=2, epochs=200, start_epoch=0, batch_size=512, optimizer='sgd', scheduler='multi', lr=0.1, lr_decay='100,150,180', weight_decay=0.0005, print_freq=20, pretrain=None, resume=None, weight_bit_width=4, act_bit_width=4, rank=1, groups=1, wandb_log=False)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, fields\n",
    "from typing import get_type_hints\n",
    "\n",
    "config_dict = {\n",
    "    \"results_dir\": \"./results\",\n",
    "    \"dataset\": \"cifar10\",\n",
    "    \"train_split\": \"train\",\n",
    "    \"model\": \"resnet20q\",\n",
    "    \"workers\": 2,\n",
    "    \"epochs\": 200,\n",
    "    \"start_epoch\": 0,\n",
    "    \"batch_size\": 512,\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"scheduler\": \"multi\",\n",
    "    \"lr\": 0.1,\n",
    "    \"lr_decay\": \"100,150,180\",\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"print_freq\": 20,\n",
    "    \"pretrain\": None,\n",
    "    \"resume\": None,\n",
    "    \"weight_bit_width\": 4,\n",
    "    \"act_bit_width\": 4,\n",
    "    \"rank\": 1,\n",
    "    \"groups\": 1,\n",
    "    \"wandb_log\": False,\n",
    "}\n",
    "\n",
    "def validate_types(my_object):\n",
    "    type_hints = get_type_hints(my_object.__class__)\n",
    "    for field_name, field_type in type_hints.items():\n",
    "        value = getattr(my_object, field_name)\n",
    "        if isinstance(value, list):\n",
    "            if not all(isinstance(item, field_type) for item in value):\n",
    "                raise ValueError(f\"All elements of '{field_name}' must be of type {field_type}\")\n",
    "        else:\n",
    "            if not isinstance(value, field_type) and value is not None:\n",
    "                raise TypeError(f\"Field '{field_name}' expected type {field_type}, got value {value} of type {type(value)}\")\n",
    "\n",
    "def set_all_fields_to_none(my_object):\n",
    "    for field in fields(my_object)[1:]:\n",
    "        setattr(my_object, field.name, None)\n",
    "\n",
    "@dataclass\n",
    "class NN_config:\n",
    "    results_dir: str = './results'\n",
    "    dataset: str = 'cifar10'\n",
    "    train_split: str = 'train'\n",
    "    model: str = 'resnet20q'\n",
    "    workers: int = 2\n",
    "    epochs: int = 200\n",
    "    start_epoch: int = 0\n",
    "    batch_size: int = 512\n",
    "    optimizer: str = 'sgd'\n",
    "    scheduler: str = 'multi'\n",
    "    lr: float = 0.1\n",
    "    lr_decay: str = '100,150,180'\n",
    "    weight_decay: float = 5e-4\n",
    "    print_freq: int = 20\n",
    "    pretrain: str = None\n",
    "    resume: str = None\n",
    "    weight_bit_width: int = 4\n",
    "    act_bit_width: int = 4\n",
    "    rank: int = 1\n",
    "    groups: int = 1\n",
    "    wandb_log: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        validate_types(self)\n",
    "        # type_hints = get_type_hints(self.__class__)\n",
    "        # for field_name, field_type in type_hints.items():\n",
    "        #     value = getattr(self, field_name)\n",
    "        #     if isinstance(value, List):\n",
    "        #         if not all(isinstance(item, field_type) for item in value):\n",
    "        #             raise ValueError(f\"All elements of '{field_name}' must be of type {field_type}\")\n",
    "        #     else:\n",
    "        #         if not isinstance(value, field_type) and value is not None:\n",
    "        #             raise TypeError(f\"Field '{field_name}' expected type {field_type}, got value {value} of type {type(value)}\")\n",
    "\n",
    "# Assuming config is the dictionary containing your configuration\n",
    "config_dataclass = NN_config(**config_dict)\n",
    "\n",
    "# Printing to verify its contents\n",
    "print(config_dataclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_config(LR_enabled=False, rank=None, groups=None)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class LR_config:\n",
    "    LR_enabled: bool = True\n",
    "    rank: int = 1\n",
    "    groups: int = 1\n",
    "\n",
    "    def __post_init__(self):\n",
    "        validate_types(self)\n",
    "        if not self.LR_enabled:\n",
    "            # set all fields to None\n",
    "            set_all_fields_to_none(self)\n",
    "\n",
    "LR_config_dict = {\n",
    "    \"LR_enabled\": False,\n",
    "    \"rank\": 1,\n",
    "    \"groups\": 1\n",
    "}\n",
    "\n",
    "LR_config_dc = LR_config(**LR_config_dict)\n",
    "print(LR_config_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class wandb_config:\n",
    "    key: str\n",
    "    project: str\n",
    "    sweep_enabled: bool\n",
    "    sweep_config: dict\n",
    "    sweep_count: int\n",
    "    sweep_id: str = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        validate_types(self)\n",
    "        if not self.sweep_enabled:\n",
    "            self.sweep_config = None\n",
    "            self.sweep_count = None\n",
    "            self.sweep_id = None\n",
    "        if self.sweep_id is not None:\n",
    "            self.sweep_config = None\n",
    "            self.sweep_count = None\n",
    "\n",
    "wandb_cfg = {\n",
    "    \"key\": \"e0c11d3ff2bee4c8775ba05863038fdac671c043\",\n",
    "    \"project\": \"wandb_plugin_dev_test\",\n",
    "    \"sweep_enabled\": True,\n",
    "    \"sweep_config\": {\n",
    "        \"method\": \"grid\",\n",
    "        \"metric\": {\"goal\": \"maximize\", \"name\": \"Best_score\"}\n",
    "    },\n",
    "    \"sweep_count\": 5,\n",
    "    \"sweep_id\": None\n",
    "}\n",
    "\n",
    "wandb_config_instance = wandb_config(**wandb_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| asdict(config_dataclass): {'act_bit_width': 4,\n",
      "                               'batch_size': 512,\n",
      "                               'dataset': 'cifar10',\n",
      "                               'epochs': 200,\n",
      "                               'groups': 1,\n",
      "                               'lr': 0.1,\n",
      "                               'lr_decay': '100,150,180',\n",
      "                               'model': 'resnet20q',\n",
      "                               'optimizer': 'sgd',\n",
      "                               'pretrain': None,\n",
      "                               'print_freq': 20,\n",
      "                               'rank': 1,\n",
      "                               'results_dir': './results',\n",
      "                               'resume': None,\n",
      "                               'scheduler': 'multi',\n",
      "                               'start_epoch': 0,\n",
      "                               'train_split': 'train',\n",
      "                               'wandb_log': False,\n",
      "                               'weight_bit_width': 4,\n",
      "                               'weight_decay': 0.0005,\n",
      "                               'workers': 2}\n",
      "ic| asdict(LR_config_dc): {'LR_enabled': False, 'groups': None, 'rank': None}\n",
      "ic| asdict(wandb_config_instance): {'key': 'e0c11d3ff2bee4c8775ba05863038fdac671c043',\n",
      "                                    'project': 'wandb_plugin_dev_test',\n",
      "                                    'sweep_config': {'method': 'grid',\n",
      "                                                     'metric': {'goal': 'maximize', 'name': 'Best_score'}},\n",
      "                                    'sweep_count': 5,\n",
      "                                    'sweep_enabled': True,\n",
      "                                    'sweep_id': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'key': 'e0c11d3ff2bee4c8775ba05863038fdac671c043',\n",
       " 'project': 'wandb_plugin_dev_test',\n",
       " 'sweep_enabled': True,\n",
       " 'sweep_config': {'method': 'grid',\n",
       "  'metric': {'goal': 'maximize', 'name': 'Best_score'}},\n",
       " 'sweep_count': 5,\n",
       " 'sweep_id': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(asdict(config_dataclass))\n",
    "ic(asdict(LR_config_dc))\n",
    "ic(asdict(wandb_config_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "def combine_dc_to_dict(dataclass_list: list) -> Dict[str, Any]:\n",
    "    combined_dict = {}\n",
    "    for dc in dataclass_list:\n",
    "        curr_dict = asdict(dc)\n",
    "        combined_dict = {**combined_dict, **curr_dict}\n",
    "    return combined_dict\n",
    "\n",
    "combined_dict = combine_dc_to_dict([config_dataclass, LR_config_dc, wandb_config_instance])\n",
    "ic(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import make_dataclass\n",
    "\n",
    "def create_dc_from_dict(name, data_dict):\n",
    "    return make_dataclass(name, data_dict.items())\n",
    "\n",
    "all_config = create_dc_from_dict(\"all_config\", combined_dict)\n",
    "all_config_instance = all_config(**combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_config_instance.results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_config(results_dir='./results', dataset='imagenet', train_split='train', model='resnet18', workers=0, epochs=200, start_epoch=0, batch_size=128, optimizer='sgd', scheduler='cosine', lr=0.1, lr_decay='100,150,180', weight_decay=0.0003, print_freq=20, pretrain=None, resume=None, bit_width_list='4', act_bit_width_list='4', rank=1, groups=1, wandb_log='hi')\n"
     ]
    }
   ],
   "source": [
    "config['wandb_log'] ='hi'\n",
    "\n",
    "# Assuming config is the dictionary containing your configuration\n",
    "config_dataclass = NN_config(**config)\n",
    "\n",
    "# Printing to verify its contents\n",
    "print(config_dataclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_config(a=test(a=[1, 2, 3, 'a']), b=test2(a=False))\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class test:\n",
    "    a: List[int]\n",
    "\n",
    "@dataclass\n",
    "class test2:\n",
    "    a: bool = False\n",
    "\n",
    "@dataclass\n",
    "class all_config:\n",
    "    a: test\n",
    "    b: test2    \n",
    "\n",
    "testing_class = test(a=[1,2,3,'a'])\n",
    "testing_class2 = test2()\n",
    "all_testing = all_config(a=testing_class, b=testing_class2)\n",
    "\n",
    "print(all_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test(a=[1, 2, 3, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_type_hints(testing_class.__class__)['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.__args__[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_value = getattr(self, field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance([1,2,3], typing.List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
